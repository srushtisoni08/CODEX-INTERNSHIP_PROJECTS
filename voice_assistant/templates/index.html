<!-- <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
        }

        .container {
            text-align: center;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
            border: 1px solid rgba(255, 255, 255, 0.18);
            max-width: 600px;
            width: 90%;
        }

        h1 {
            margin-bottom: 30px;
            font-size: 2.5rem;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(45deg, #ff6b6b, #ee5a52);
            color: white;
            font-size: 2rem;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.3);
            margin: 20px;
            display: inline-flex;
            align-items: center;
            justify-content: center;
        }

        .mic-button:hover {
            transform: scale(1.1);
            box-shadow: 0 12px 35px rgba(0, 0, 0, 0.4);
        }

        .mic-button:active {
            transform: scale(0.95);
        }

        .mic-button.recording {
            background: linear-gradient(45deg, #ff4757, #ff3838);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .status {
            margin: 20px 0;
            font-size: 1.2rem;
            min-height: 30px;
            opacity: 0.8;
        }

        .response {
            background: rgba(255, 255, 255, 0.2);
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            min-height: 100px;
            max-height: 200px;
            overflow-y: auto;
            text-align: left;
            font-size: 1.1rem;
            line-height: 1.6;
            box-shadow: inset 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .controls {
            margin-top: 30px;
        }

        .control-button {
            background: rgba(255, 255, 255, 0.2);
            border: 1px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 10px 20px;
            border-radius: 25px;
            margin: 5px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 0.9rem;
        }

        .control-button:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }

        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top-color: white;
            animation: spin 1s ease-in-out infinite;
            margin-right: 10px;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        .audio-controls {
            margin-top: 15px;
        }

        audio {
            width: 100%;
            max-width: 300px;
            margin: 10px 0;
        }

        .error {
            color: #ff6b6b;
            background: rgba(255, 107, 107, 0.1);
            border: 1px solid rgba(255, 107, 107, 0.3);
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
        }

        .success {
            color: #51cf66;
            background: rgba(81, 207, 102, 0.1);
            border: 1px solid rgba(81, 207, 102, 0.3);
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .mic-button {
                width: 100px;
                height: 100px;
                font-size: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Voice Assistant</h1>
        
        <div class="status" id="status">Click the microphone to start</div>
        
        <button class="mic-button" id="micButton" onclick="toggleRecording()">
            üé§
        </button>
        
        <div class="response" id="response">
            <p>Hello! I'm your voice assistant. I can help you with:</p>
            <ul>
                <li>üå§Ô∏è Weather information</li>
                <li>üì∞ Latest news</li>
                <li>‚è∞ Current time and date</li>
                <li>üìù Setting reminders</li>
                <li>üí¨ General conversation</li>
            </ul>
            <p>Just click the microphone and start speaking!</p>
        </div>
        
        <div class="audio-controls" id="audioControls" style="display: none;">
            <audio id="responseAudio" controls></audio>
        </div>
        
        <div class="controls">
            <button class="control-button" onclick="clearResponse()">Clear Response</button>
            <button class="control-button" onclick="viewReminders()">View Reminders</button>
            <button class="control-button" onclick="clearReminders()">Clear Reminders</button>
        </div>
    </div>

    <script>
        let audioContext;
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let stream;
        let processor;

        const micButton = document.getElementById('micButton');
        const status = document.getElementById('status');
        const response = document.getElementById('response');
        const audioControls = document.getElementById('audioControls');
        const responseAudio = document.getElementById('responseAudio');

        // Initialize audio context
        async function initAudioContext() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                return true;
            } catch (error) {
                console.error('Audio context initialization failed:', error);
                return false;
            }
        }

        // Convert audio buffer to WAV format
        function audioBufferToWav(buffer, length) {
            const arrayBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(arrayBuffer);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            const sampleRate = buffer.sampleRate;
            const channels = 1; // Mono
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, channels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            // Convert float samples to 16-bit PCM
            const channelData = buffer.getChannelData(0);
            let offset = 44;
            for (let i = 0; i < length; i++) {
                const sample = Math.max(-1, Math.min(1, channelData[i]));
                view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                offset += 2;
            }
            
            return arrayBuffer;
        }

        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        }

        async function startRecording() {
            try {
                // Initialize audio context if needed
                if (!audioContext) {
                    const initialized = await initAudioContext();
                    if (!initialized) {
                        throw new Error('Could not initialize audio context');
                    }
                }

                // Resume audio context if suspended
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }

                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 44100,
                        channelCount: 1
                    } 
                });

                const source = audioContext.createMediaStreamSource(stream);
                
                // Create a script processor for recording
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                audioChunks = [];

                processor.onaudioprocess = (e) => {
                    const inputData = e.inputBuffer.getChannelData(0);
                    audioChunks.push(new Float32Array(inputData));
                };

                source.connect(processor);
                processor.connect(audioContext.destination);

                isRecording = true;
                micButton.classList.add('recording');
                micButton.innerHTML = 'üõë';
                status.innerHTML = '<div class="loading"></div>Recording... Click to stop';

            } catch (error) {
                console.error('Error starting recording:', error);
                if (error.name === 'NotAllowedError') {
                    showError('Microphone permission denied. Please allow microphone access and refresh the page.');
                } else if (error.name === 'NotFoundError') {
                    showError('No microphone found. Please connect a microphone and try again.');
                } else {
                    showError('Recording error: ' + error.message);
                }
            }
        }

        function stopRecording() {
            if (!isRecording) return;

            isRecording = false;
            micButton.classList.remove('recording');
            micButton.innerHTML = 'üé§';
            status.innerHTML = '<div class="loading"></div>Processing audio...';

            // Stop the processor and stream
            if (processor) {
                processor.disconnect();
                processor = null;
            }

            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }

            // Process recorded audio chunks
            if (audioChunks.length === 0) {
                showError('No audio recorded. Please try again.');
                status.textContent = 'Ready to try again';
                return;
            }

            // Combine all chunks
            let totalLength = 0;
            audioChunks.forEach(chunk => {
                totalLength += chunk.length;
            });

            const combinedData = new Float32Array(totalLength);
            let offset = 0;
            audioChunks.forEach(chunk => {
                combinedData.set(chunk, offset);
                offset += chunk.length;
            });

            // Create audio buffer
            const audioBuffer = audioContext.createBuffer(1, totalLength, audioContext.sampleRate);
            audioBuffer.copyToChannel(combinedData, 0);

            // Convert to WAV
            const wavArrayBuffer = audioBufferToWav(audioBuffer, totalLength);
            const wavBlob = new Blob([wavArrayBuffer], { type: 'audio/wav' });

            console.log('Generated WAV blob:', wavBlob.size, 'bytes');
            sendAudioToServer(wavBlob);
        }

        async function sendAudioToServer(audioBlob) {
            const formData = new FormData();
            formData.append('audio_data', audioBlob, 'audio.wav');

            try {
                const response_data = await fetch('/process_audio', {
                    method: 'POST',
                    body: formData
                });

                const result = await response_data.json();
                
                if (response_data.ok) {
                    if (result.recognized_text) {
                        displayResponse(`<div class="success"><strong>‚úÖ You said:</strong> "${result.recognized_text}"</div><br><div><strong>ü§ñ Assistant:</strong> ${result.response}</div>`);
                    } else {
                        displayResponse(result.response);
                    }
                    await generateSpeech(result.response);
                    status.textContent = 'Ready for next command';
                } else {
                    showError(result.response || 'Error processing audio');
                    status.textContent = 'Ready to try again';
                }
            } catch (error) {
                console.error('Network error:', error);
                showError('Network error. Please check your internet connection and try again.');
                status.textContent = 'Ready to try again';
            }
        }

        async function generateSpeech(text) {
            try {
                const response_data = await fetch('/speak', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ text: text })
                });

                const result = await response_data.json();
                
                if (response_data.ok && result.audio_url) {
                    responseAudio.src = result.audio_url;
                    audioControls.style.display = 'block';
                    
                    try {
                        await responseAudio.play();
                    } catch (playError) {
                        console.log('Auto-play blocked by browser');
                    }
                } else {
                    console.error('Speech generation failed:', result.error);
                }
            } catch (error) {
                console.error('Error generating speech:', error);
            }
        }

        function displayResponse(text) {
            response.innerHTML = `<div class="success">${text}</div>`;
        }

        function showError(message) {
            response.innerHTML = `<div class="error">${message}</div>`;
        }

        function clearResponse() {
            response.innerHTML = `
                <p>Hello! I'm your voice assistant. I can help you with:</p>
                <ul>
                    <li>üå§Ô∏è Weather information</li>
                    <li>üì∞ Latest news</li>
                    <li>‚è∞ Current time and date</li>
                    <li>üìù Setting reminders</li>
                    <li>üí¨ General conversation</li>
                </ul>
                <p>Just click the microphone and start speaking!</p>
            `;
            audioControls.style.display = 'none';
            status.textContent = 'Click the microphone to start';
        }

        async function viewReminders() {
            try {
                const response_data = await fetch('/reminders');
                const result = await response_data.json();
                
                if (result.reminders && result.reminders.length > 0) {
                    let reminderText = '<h3>Your Reminders:</h3><ul>';
                    result.reminders.forEach((reminder, index) => {
                        reminderText += `<li><strong>${reminder.text}</strong> <br><small>Set on: ${new Date(reminder.time).toLocaleString()}</small></li>`;
                    });
                    reminderText += '</ul>';
                    response.innerHTML = reminderText;
                } else {
                    response.innerHTML = '<div class="success">No reminders found.</div>';
                }
            } catch (error) {
                showError('Failed to load reminders.');
            }
        }

        async function clearReminders() {
            try {
                const response_data = await fetch('/reminders', { method: 'DELETE' });
                const result = await response_data.json();
                
                if (response_data.ok) {
                    response.innerHTML = '<div class="success">All reminders cleared!</div>';
                } else {
                    showError('Failed to clear reminders.');
                }
            } catch (error) {
                showError('Failed to clear reminders.');
            }
        }

        // Check for browser support
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            showError('Your browser does not support audio recording. Please use a modern browser like Chrome, Firefox, or Safari.');
            micButton.disabled = true;
        }

        // Initialize audio context on user interaction
        document.addEventListener('click', () => {
            if (!audioContext) {
                initAudioContext();
            }
        }, { once: true });
    </script>
</body>
</html> -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #6a11cb;
            --secondary-color: #2575fc;
            --container-bg: rgba(255, 255, 255, 0.1);
            --container-border: rgba(255, 255, 255, 0.18);
            --shadow-color: rgba(31, 38, 135, 0.37);
            --red-color: #e53935;
            --green-color: #43a047;
            --text-color: #ffffff;
            --soft-white: rgba(255, 255, 255, 0.8);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Poppins', sans-serif;
            background: linear-gradient(135deg, #1f2746 0%, #101525 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            color: var(--text-color);
            transition: background 0.5s ease;
        }

        .container {
            text-align: center;
            background: var(--container-bg);
            backdrop-filter: blur(20px);
            -webkit-backdrop-filter: blur(20px);
            border-radius: 25px;
            padding: 50px 30px;
            box-shadow: 0 10px 40px 0 var(--shadow-color);
            border: 1px solid var(--container-border);
            max-width: 650px;
            width: 90%;
        }

        h1 {
            margin-bottom: 25px;
            font-size: 2.5rem;
            font-weight: 600;
            text-shadow: 1px 1px 3px rgba(0, 0, 0, 0.5);
            letter-spacing: 1px;
        }

        .mic-button {
            width: 140px;
            height: 140px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(145deg, #6a11cb, #2575fc);
            color: white;
            font-size: 2.5rem;
            cursor: pointer;
            transition: all 0.4s cubic-bezier(0.25, 0.8, 0.25, 1);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.4);
            margin: 20px 0;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            border: 5px solid rgba(255, 255, 255, 0.2);
        }

        .mic-button:hover {
            transform: translateY(-5px) scale(1.05);
            box-shadow: 0 15px 30px rgba(0, 0, 0, 0.5);
        }

        .mic-button:active {
            transform: scale(0.95);
        }

        .mic-button.recording {
            background: linear-gradient(145deg, #e53935, #ff5722);
            animation: pulse 1.8s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); box-shadow: 0 0 0 0 rgba(229, 57, 53, 0.7); }
            70% { transform: scale(1.1); box-shadow: 0 0 0 20px rgba(229, 57, 53, 0); }
            100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(229, 57, 53, 0); }
        }

        .status {
            margin: 20px 0 30px;
            font-size: 1.1rem;
            min-height: 25px;
            opacity: 0.9;
        }

        .status .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid var(--soft-white);
            border-radius: 50%;
            border-top-color: var(--primary-color);
            animation: spin 1s linear infinite;
            vertical-align: middle;
            margin-right: 10px;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        .response {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 15px;
            padding: 25px;
            margin: 20px 0;
            min-height: 120px;
            max-height: 250px;
            overflow-y: auto;
            text-align: left;
            font-size: 1rem;
            line-height: 1.8;
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: inset 0 2px 5px rgba(0, 0, 0, 0.1);
        }

        .response ul {
            list-style: none;
            padding-left: 0;
            margin-top: 15px;
        }

        .response ul li {
            padding: 5px 0;
            border-bottom: 1px dashed rgba(255, 255, 255, 0.1);
        }

        .response ul li:last-child {
            border-bottom: none;
        }
        
        .response::-webkit-scrollbar {
            width: 8px;
        }

        .response::-webkit-scrollbar-thumb {
            background-color: rgba(255, 255, 255, 0.3);
            border-radius: 10px;
        }

        .response::-webkit-scrollbar-track {
            background-color: transparent;
        }

        .controls {
            margin-top: 30px;
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 15px;
        }

        .control-button {
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: var(--text-color);
            padding: 12px 25px;
            border-radius: 30px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 0.95rem;
            font-weight: 500;
        }

        .control-button:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-2px);
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
        }

        .audio-controls {
            margin-top: 20px;
        }

        audio {
            width: 100%;
            max-width: 350px;
            margin: 15px auto;
            display: block;
        }

        audio::-webkit-media-controls-panel {
            background-color: rgba(255, 255, 255, 0.2);
            border-radius: 50px;
            color: white;
        }

        .error, .success {
            padding: 15px 20px;
            border-radius: 12px;
            margin: 15px 0;
            font-weight: 500;
        }

        .error {
            color: var(--red-color);
            background: rgba(229, 57, 53, 0.1);
            border: 1px solid rgba(229, 57, 53, 0.3);
        }

        .success {
            color: var(--green-color);
            background: rgba(67, 160, 71, 0.1);
            border: 1px solid rgba(67, 160, 71, 0.3);
        }

        @media (max-width: 768px) {
            .container {
                padding: 30px 15px;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .mic-button {
                width: 110px;
                height: 110px;
                font-size: 2rem;
            }

            .controls {
                flex-direction: column;
                gap: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üó£Ô∏è Talk to me</h1>
        
        <div class="status" id="status">Click the microphone to start</div>
        
        <button class="mic-button" id="micButton" onclick="toggleRecording()">
            üé§
        </button>
        
        <div class="response" id="response">
            <p><strong>Hello! I'm your voice assistant.</strong></p>
            <p>I can assist you with a range of tasks:</p>
            <ul>
                <li>üå§Ô∏è Weather information</li>
                <li>üì∞ Latest news headlines</li>
                <li>‚è∞ Current time and date</li>
                <li>üìù Setting reminders for you</li>
                <li>üí¨ General conversation and questions</li>
            </ul>
            <p>Just press the microphone and start speaking!</p>
        </div>
        
        <div class="audio-controls" id="audioControls" style="display: none;">
            <audio id="responseAudio" controls></audio>
        </div>
        
        <div class="controls">
            <button class="control-button" onclick="clearResponse()">Clear Response</button>
            <button class="control-button" onclick="viewReminders()">View Reminders</button>
            <button class="control-button" onclick="clearReminders()">Clear Reminders</button>
        </div>
    </div>

    <script>
        let audioContext;
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let stream;
        let processor;

        const micButton = document.getElementById('micButton');
        const status = document.getElementById('status');
        const response = document.getElementById('response');
        const audioControls = document.getElementById('audioControls');
        const responseAudio = document.getElementById('responseAudio');

        // Initialize audio context
        async function initAudioContext() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                return true;
            } catch (error) {
                console.error('Audio context initialization failed:', error);
                return false;
            }
        }

        // Convert audio buffer to WAV format
        function audioBufferToWav(buffer, length) {
            const arrayBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(arrayBuffer);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            const sampleRate = buffer.sampleRate;
            const channels = 1; // Mono
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, channels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            // Convert float samples to 16-bit PCM
            const channelData = buffer.getChannelData(0);
            let offset = 44;
            for (let i = 0; i < length; i++) {
                const sample = Math.max(-1, Math.min(1, channelData[i]));
                view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                offset += 2;
            }
            
            return arrayBuffer;
        }

        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        }

        async function startRecording() {
            try {
                // Initialize audio context if needed
                if (!audioContext) {
                    const initialized = await initAudioContext();
                    if (!initialized) {
                        throw new Error('Could not initialize audio context');
                    }
                }

                // Resume audio context if suspended
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }

                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 44100,
                        channelCount: 1
                    } 
                });

                const source = audioContext.createMediaStreamSource(stream);
                
                // Create a script processor for recording
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                audioChunks = [];

                processor.onaudioprocess = (e) => {
                    const inputData = e.inputBuffer.getChannelData(0);
                    audioChunks.push(new Float32Array(inputData));
                };

                source.connect(processor);
                processor.connect(audioContext.destination);

                isRecording = true;
                micButton.classList.add('recording');
                micButton.innerHTML = 'üõë';
                status.innerHTML = '<div class="loading"></div>Recording... Click to stop';

            } catch (error) {
                console.error('Error starting recording:', error);
                if (error.name === 'NotAllowedError') {
                    showError('Microphone permission denied. Please allow microphone access and refresh the page.');
                } else if (error.name === 'NotFoundError') {
                    showError('No microphone found. Please connect a microphone and try again.');
                } else {
                    showError('Recording error: ' + error.message);
                }
            }
        }

        function stopRecording() {
            if (!isRecording) return;

            isRecording = false;
            micButton.classList.remove('recording');
            micButton.innerHTML = 'üé§';
            status.innerHTML = '<div class="loading"></div>Processing audio...';

            // Stop the processor and stream
            if (processor) {
                processor.disconnect();
                processor = null;
            }

            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }

            // Process recorded audio chunks
            if (audioChunks.length === 0) {
                showError('No audio recorded. Please try again.');
                status.textContent = 'Ready to try again';
                return;
            }

            // Combine all chunks
            let totalLength = 0;
            audioChunks.forEach(chunk => {
                totalLength += chunk.length;
            });

            const combinedData = new Float32Array(totalLength);
            let offset = 0;
            audioChunks.forEach(chunk => {
                combinedData.set(chunk, offset);
                offset += chunk.length;
            });

            // Create audio buffer
            const audioBuffer = audioContext.createBuffer(1, totalLength, audioContext.sampleRate);
            audioBuffer.copyToChannel(combinedData, 0);

            // Convert to WAV
            const wavArrayBuffer = audioBufferToWav(audioBuffer, totalLength);
            const wavBlob = new Blob([wavArrayBuffer], { type: 'audio/wav' });

            console.log('Generated WAV blob:', wavBlob.size, 'bytes');
            sendAudioToServer(wavBlob);
        }

        async function sendAudioToServer(audioBlob) {
            const formData = new FormData();
            formData.append('audio_data', audioBlob, 'audio.wav');

            try {
                const response_data = await fetch('/process_audio', {
                    method: 'POST',
                    body: formData
                });

                const result = await response_data.json();
                
                if (response_data.ok) {
                    if (result.recognized_text) {
                        displayResponse(`<div class="success"><strong>‚úÖ You said:</strong> "${result.recognized_text}"</div><br><div><strong>ü§ñ Assistant:</strong> ${result.response}</div>`);
                    } else {
                        displayResponse(result.response);
                    }
                    await generateSpeech(result.response);
                    status.textContent = 'Ready for next command';
                } else {
                    showError(result.response || 'Error processing audio');
                    status.textContent = 'Ready to try again';
                }
            } catch (error) {
                console.error('Network error:', error);
                showError('Network error. Please check your internet connection and try again.');
                status.textContent = 'Ready to try again';
            }
        }

        async function generateSpeech(text) {
            try {
                const response_data = await fetch('/speak', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ text: text })
                });

                const result = await response_data.json();
                
                if (response_data.ok && result.audio_url) {
                    responseAudio.src = result.audio_url;
                    audioControls.style.display = 'block';
                    
                    try {
                        await responseAudio.play();
                    } catch (playError) {
                        console.log('Auto-play blocked by browser');
                    }
                } else {
                    console.error('Speech generation failed:', result.error);
                }
            } catch (error) {
                console.error('Error generating speech:', error);
            }
        }

        function displayResponse(text) {
            response.innerHTML = text;
        }

        function showError(message) {
            response.innerHTML = `<div class="error">${message}</div>`;
        }

        function clearResponse() {
            response.innerHTML = `
                <p><strong>Hello! I'm your voice assistant.</strong></p>
                <p>I can assist you with a range of tasks:</p>
                <ul>
                    <li>üå§Ô∏è Weather information</li>
                    <li>üì∞ Latest news headlines</li>
                    <li>‚è∞ Current time and date</li>
                    <li>üìù Setting reminders for you</li>
                    <li>üí¨ General conversation and questions</li>
                </ul>
                <p>Just press the microphone and start speaking!</p>
            `;
            audioControls.style.display = 'none';
            status.textContent = 'Click the microphone to start';
        }

        async function viewReminders() {
            try {
                const response_data = await fetch('/reminders');
                const result = await response_data.json();
                
                if (result.reminders && result.reminders.length > 0) {
                    let reminderText = `<h3><div class="success">Your Reminders:</div></h3><ul>`;
                    result.reminders.forEach((reminder, index) => {
                        reminderText += `<li><strong>${reminder.text}</strong> <br><small>Set on: ${new Date(reminder.time).toLocaleString()}</small></li>`;
                    });
                    reminderText += '</ul>';
                    response.innerHTML = reminderText;
                } else {
                    response.innerHTML = '<div class="success">No reminders found.</div>';
                }
            } catch (error) {
                showError('Failed to load reminders.');
            }
        }

        async function clearReminders() {
            try {
                const response_data = await fetch('/reminders', { method: 'DELETE' });
                const result = await response_data.json();
                
                if (response_data.ok) {
                    response.innerHTML = '<div class="success">All reminders cleared!</div>';
                } else {
                    showError('Failed to clear reminders.');
                }
            } catch (error) {
                showError('Failed to clear reminders.');
            }
        }

        // Check for browser support
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            showError('Your browser does not support audio recording. Please use a modern browser like Chrome, Firefox, or Safari.');
            micButton.disabled = true;
        }

        // Initialize audio context on user interaction
        document.addEventListener('click', () => {
            if (!audioContext) {
                initAudioContext();
            }
        }, { once: true });
    </script>
</body>
</html>