<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600&display=swap" rel="stylesheet">
    <link href="../static/style.css" rel="stylesheet">
    <style>
        :root {
            --primary-color: #6a11cb;
            --secondary-color: #2575fc;
            --container-bg: rgba(255, 255, 255, 0.1);
            --container-border: rgba(255, 255, 255, 0.18);
            --shadow-color: rgba(31, 38, 135, 0.37);
            --red-color: #e53935;
            --green-color: #43a047;
            --text-color: #ffffff;
            --soft-white: rgba(255, 255, 255, 0.8);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        
    </style>
</head>
<body>
    <div class="container">
        <h1>üó£Ô∏è Talk to me</h1>
        
        <div class="status" id="status">Click the microphone to start</div>
        
        <button class="mic-button" id="micButton" onclick="toggleRecording()">
            üé§
        </button>
        
        <div class="response" id="response">
            <p><strong>Hello! I'm your voice assistant.</strong></p>
            <p>I can assist you with a range of tasks:</p>
            <ul>
                <li>üå§Ô∏è Weather information</li>
                <li>üì∞ Latest news headlines</li>
                <li>‚è∞ Current time and date</li>
                <li>üìù Setting reminders for you</li>
                <li>üí¨ General conversation and questions</li>
            </ul>
            <p>Just press the microphone and start speaking!</p>
        </div>
        
        <div class="audio-controls" id="audioControls" style="display: none;">
            <audio id="responseAudio" controls></audio>
        </div>
        
        <div class="controls">
            <button class="control-button" onclick="clearResponse()">Clear Response</button>
            <button class="control-button" onclick="viewReminders()">View Reminders</button>
            <button class="control-button" onclick="clearReminders()">Clear Reminders</button>
        </div>
    </div>

    <script>
        let audioContext;
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let stream;
        let processor;

        const micButton = document.getElementById('micButton');
        const status = document.getElementById('status');
        const response = document.getElementById('response');
        const audioControls = document.getElementById('audioControls');
        const responseAudio = document.getElementById('responseAudio');

        // Initialize audio context
        async function initAudioContext() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                return true;
            } catch (error) {
                console.error('Audio context initialization failed:', error);
                return false;
            }
        }

        // Convert audio buffer to WAV format
        function audioBufferToWav(buffer, length) {
            const arrayBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(arrayBuffer);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            const sampleRate = buffer.sampleRate;
            const channels = 1; // Mono
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, channels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            // Convert float samples to 16-bit PCM
            const channelData = buffer.getChannelData(0);
            let offset = 44;
            for (let i = 0; i < length; i++) {
                const sample = Math.max(-1, Math.min(1, channelData[i]));
                view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                offset += 2;
            }
            
            return arrayBuffer;
        }

        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        }

        async function startRecording() {
            try {
                // Initialize audio context if needed
                if (!audioContext) {
                    const initialized = await initAudioContext();
                    if (!initialized) {
                        throw new Error('Could not initialize audio context');
                    }
                }

                // Resume audio context if suspended
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                }

                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 44100,
                        channelCount: 1
                    } 
                });

                const source = audioContext.createMediaStreamSource(stream);
                
                // Create a script processor for recording
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                audioChunks = [];

                processor.onaudioprocess = (e) => {
                    const inputData = e.inputBuffer.getChannelData(0);
                    audioChunks.push(new Float32Array(inputData));
                };

                source.connect(processor);
                processor.connect(audioContext.destination);

                isRecording = true;
                micButton.classList.add('recording');
                micButton.innerHTML = 'üõë';
                status.innerHTML = '<div class="loading"></div>Recording... Click to stop';

            } catch (error) {
                console.error('Error starting recording:', error);
                if (error.name === 'NotAllowedError') {
                    showError('Microphone permission denied. Please allow microphone access and refresh the page.');
                } else if (error.name === 'NotFoundError') {
                    showError('No microphone found. Please connect a microphone and try again.');
                } else {
                    showError('Recording error: ' + error.message);
                }
            }
        }

        function stopRecording() {
            if (!isRecording) return;

            isRecording = false;
            micButton.classList.remove('recording');
            micButton.innerHTML = 'üé§';
            status.innerHTML = '<div class="loading"></div>Processing audio...';

            // Stop the processor and stream
            if (processor) {
                processor.disconnect();
                processor = null;
            }

            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }

            // Process recorded audio chunks
            if (audioChunks.length === 0) {
                showError('No audio recorded. Please try again.');
                status.textContent = 'Ready to try again';
                return;
            }

            // Combine all chunks
            let totalLength = 0;
            audioChunks.forEach(chunk => {
                totalLength += chunk.length;
            });

            const combinedData = new Float32Array(totalLength);
            let offset = 0;
            audioChunks.forEach(chunk => {
                combinedData.set(chunk, offset);
                offset += chunk.length;
            });

            // Create audio buffer
            const audioBuffer = audioContext.createBuffer(1, totalLength, audioContext.sampleRate);
            audioBuffer.copyToChannel(combinedData, 0);

            // Convert to WAV
            const wavArrayBuffer = audioBufferToWav(audioBuffer, totalLength);
            const wavBlob = new Blob([wavArrayBuffer], { type: 'audio/wav' });

            console.log('Generated WAV blob:', wavBlob.size, 'bytes');
            sendAudioToServer(wavBlob);
        }

        async function sendAudioToServer(audioBlob) {
            const formData = new FormData();
            formData.append('audio_data', audioBlob, 'audio.wav');

            try {
                const response_data = await fetch('/process_audio', {
                    method: 'POST',
                    body: formData
                });

                const result = await response_data.json();
                
                if (response_data.ok) {
                    if (result.recognized_text) {
                        displayResponse(`<div class="success"><strong>‚úÖ You said:</strong> "${result.recognized_text}"</div><br><div><strong>ü§ñ Assistant:</strong> ${result.response}</div>`);
                    } else {
                        displayResponse(result.response);
                    }
                    await generateSpeech(result.response);
                    status.textContent = 'Ready for next command';
                } else {
                    showError(result.response || 'Error processing audio');
                    status.textContent = 'Ready to try again';
                }
            } catch (error) {
                console.error('Network error:', error);
                showError('Network error. Please check your internet connection and try again.');
                status.textContent = 'Ready to try again';
            }
        }

        async function generateSpeech(text) {
            try {
                const response_data = await fetch('/speak', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ text: text })
                });

                const result = await response_data.json();
                
                if (response_data.ok && result.audio_url) {
                    responseAudio.src = result.audio_url;
                    audioControls.style.display = 'block';
                    
                    try {
                        await responseAudio.play();
                    } catch (playError) {
                        console.log('Auto-play blocked by browser');
                    }
                } else {
                    console.error('Speech generation failed:', result.error);
                }
            } catch (error) {
                console.error('Error generating speech:', error);
            }
        }

        function displayResponse(text) {
            response.innerHTML = text;
        }

        function showError(message) {
            response.innerHTML = `<div class="error">${message}</div>`;
        }

        function clearResponse() {
            response.innerHTML = `
                <p><strong>Hello! I'm your voice assistant.</strong></p>
                <p>I can assist you with a range of tasks:</p>
                <ul>
                    <li>üå§Ô∏è Weather information</li>
                    <li>üì∞ Latest news headlines</li>
                    <li>‚è∞ Current time and date</li>
                    <li>üìù Setting reminders for you</li>
                    <li>üí¨ General conversation and questions</li>
                </ul>
                <p>Just press the microphone and start speaking!</p>
            `;
            audioControls.style.display = 'none';
            status.textContent = 'Click the microphone to start';
        }

        async function viewReminders() {
            try {
                const response_data = await fetch('/reminders');
                const result = await response_data.json();
                
                if (result.reminders && result.reminders.length > 0) {
                    let reminderText = `<h3><div class="success">Your Reminders:</div></h3><ul>`;
                    result.reminders.forEach((reminder, index) => {
                        reminderText += `<li><strong>${reminder.text}</strong> <br><small>Set on: ${new Date(reminder.time).toLocaleString()}</small></li>`;
                    });
                    reminderText += '</ul>';
                    response.innerHTML = reminderText;
                } else {
                    response.innerHTML = '<div class="success">No reminders found.</div>';
                }
            } catch (error) {
                showError('Failed to load reminders.');
            }
        }

        async function clearReminders() {
            try {
                const response_data = await fetch('/reminders', { method: 'DELETE' });
                const result = await response_data.json();
                
                if (response_data.ok) {
                    response.innerHTML = '<div class="success">All reminders cleared!</div>';
                } else {
                    showError('Failed to clear reminders.');
                }
            } catch (error) {
                showError('Failed to clear reminders.');
            }
        }

        // Check for browser support
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            showError('Your browser does not support audio recording. Please use a modern browser like Chrome, Firefox, or Safari.');
            micButton.disabled = true;
        }

        // Initialize audio context on user interaction
        document.addEventListener('click', () => {
            if (!audioContext) {
                initAudioContext();
            }
        }, { once: true });
    </script>
</body>
</html>